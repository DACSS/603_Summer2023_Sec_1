{
  "hash": "4b2ba11836f4a76171d264032e297f95",
  "result": {
    "markdown": "---\ntitle: \"HW2\"\nauthor: \"Sue-Ellen Duffy\"\ndate: \"06/27/2023\"\noutput: pdf_document\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(summarytools)\nlibrary(readxl)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n\n# 3.8 Exercises\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#1 \n# define a function for the estimator\nY_tilde <- function(x){sum(x)/(length(x)-1)}\n\n\n# repeatedly compute estimates and store the results in est_biased\nset.seed(123)\nest_biased <-     replicate(expr = Y_tilde(rnorm(5, 10, 5)), n = 10000)     \n         \n# plot a histogram of est_biased\nhist(est_biased)         \n         \n# add a red vertical line at mu = 10\nabline(v = 10, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](HW2_duffysueellen_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#2\n# compute repeatedly estimates and store the results in est_consistent\nset.seed(123)\nest_consistent <- replicate(expr = Y_tilde(rnorm(1000, 10, 5)), n = 10000)     \n         \n# plot a histogram of est_consistent\nhist(est_consistent)\n\n# add a red vertical line at mu = 10\nabline(v = 10, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](HW2_duffysueellen_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Efficiency of an Estimator\n# verify that the alternative estimator is unbiased\nn <- 100\nw <- c(rep((1+0.5)/n, n/2), rep((1-0.5)/n, n/2))\nsum(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\n# define the alternative estimator mu_tilde\nmu_tilde <- function(x){sum(x*w)}         \n         \n# compute repeatedly estimates for both estimators and store the results in est_bar and est_tilde\nset.seed(123)\nest_bar <- replicate(expr = mean(rnorm(100, 5, 10)), n = 10000)    \nest_tilde <- replicate(expr = mu_tilde(rnorm(100, 5, 10)), n = 10000)  \nhist(est_bar)\n```\n\n::: {.cell-output-display}\n![](HW2_duffysueellen_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(est_tilde)\n```\n\n::: {.cell-output-display}\n![](HW2_duffysueellen_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# compute the sample variances for est_bar and est_tilde\nvar(est_bar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9953755\n```\n:::\n\n```{.r .cell-code}\nvar(est_tilde)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.248949\n```\n:::\n\n```{.r .cell-code}\nplot(density(est_tilde), \n     col = \"green\", \n     lwd = 2,\n     ylim = c(0, 0.5))\n\nlines(density(est_bar), \n      col = \"steelblue\", \n      lwd = 2, \n      bty = \"l\")\n```\n\n::: {.cell-output-display}\n![](HW2_duffysueellen_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# est_bar is (0.9953755) whereas est_tilde is (1.248949)\n#  This means that est_bar, being less than est_tilde is  more efficient\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4\n# compute the t statistic by hand and assign it to tstat\n# tstat <- (mean(cps$ahe12)-23.5)/(sd(cps$ahe12)/sqrt(length(cps$ahe12)))\n\n# use tstat to accept or reject the null\n# tstat > qnorm(.95)\n# [1] TRUE\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#5\n# compute the p-value by hand and assign it to pval\nahe12test <- cps$ahe12\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'cps' not found\n```\n:::\n\n```{.r .cell-code}\npval <- t.test(ahe12test)$\"p-value\"\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in t.test(ahe12test): object 'ahe12test' not found\n```\n:::\n\n```{.r .cell-code}\npval\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'pval' not found\n```\n:::\n\n```{.r .cell-code}\n# use pval to accept or reject the null\npval > .05\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'pval' not found\n```\n:::\n\n```{.r .cell-code}\n# [1] TRUE\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#6\n# conduct the hypothesis test from the previous exercises with t.test()\nt.test(cps$ahe12, alternative = \"greater\", mu = 23.5)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in t.test(cps$ahe12, alternative = \"greater\", mu = 23.5): object 'cps' not found\n```\n:::\n\n```{.r .cell-code}\n# extract t statistic and p-value from the list created by t.test()\ntstat <- t.test(cps$ahe12, alternative = \"greater\", mu = 23.5)$statistic\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in t.test(cps$ahe12, alternative = \"greater\", mu = 23.5): object 'cps' not found\n```\n:::\n\n```{.r .cell-code}\npvalue <- t.test(cps$ahe12, alternative = \"greater\", mu = 23.5)$p.value\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in t.test(cps$ahe12, alternative = \"greater\", mu = 23.5): object 'cps' not found\n```\n:::\n\n```{.r .cell-code}\n#the \"greater\" portion of this equation threw me for a loop, I'm not sure I understand it fully..\n\n\n# verify that using the normal approximation is valid here as well\npvalue - pval\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'pvalue' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#7\nt.test(portpirie, fremantle)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in t.test(portpirie, fremantle): object 'portpirie' not found\n```\n:::\n:::\n\n\n#8\n\n::: {.cell}\n\n```{.r .cell-code}\n#8\n#construct a 95%-confidence interval using t.test\n# because The function t.test() computes a 95% confidence interval by default. This is accessible via $conf.int...\n\nt.test(portpirie, fremantle)$conf.int\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in t.test(portpirie, fremantle): object 'portpirie' not found\n```\n:::\n\n```{.r .cell-code}\n# [1] 2.584 2.833\n# attr(,\"conf.level\")\n# [1] .95\n```\n:::\n\n\n#9\n\n::: {.cell}\n\n```{.r .cell-code}\ncov(X,X)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(y): object 'X' not found\n```\n:::\n\n```{.r .cell-code}\ncov(X,Y)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(y): object 'Y' not found\n```\n:::\n\n```{.r .cell-code}\ncor(X, Y)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(y): object 'Y' not found\n```\n:::\n:::\n\n\n#10\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(X, Y)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(y): object 'Y' not found\n```\n:::\n\n```{.r .cell-code}\n# -.919\n#this means the correlation is negative between X and Y... \n#as X increases, Y decreases. -1 would be a perfect negative correlation, and -0.9 is close to -1 so it is close to perfect negative correlation\n```\n:::",
    "supporting": [
      "HW2_duffysueellen_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}