---
title: "603_ClassProject"
author: "Nanci Kopecky"
description: "General Social Survey"
date: "08/17/2022"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  - Final Project
  - Kopecky
---

```{r}
#| label: setup
#| warning: false
#| message: false
# libraries

library(dplyr)
library(MASS)
library(readxl)
library(readr)
library(tidyverse)
library(ggplot2)
library(stats)
library(AER)
library(stargazer)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)

```

## Introduction

Is it more important for a wife to help her husband's career than to have one herself? This was a question on a survey on American society from 1977 to 1998. It may seem out of date in 2023, but is it? The upheaval from Covid-19 pandemic underscored the stress of balancing work and family. During this time, The National Women's Law Center stated that women left the workforce at a disproportionate rate and have not yet recovered (2022). This is a concern because of women's forfeited skills, diminished wages, and unrealized earning potential.

Additionally, the BBC reported, "Researchers for Deloitte's Women Work 2023 surveyed 5,000 women across 10 countries, 98% of whom were in heterosexual relationships. The data found that nearly 40% of respondents say their partner's career takes precedence. They cited several reasons, ranging from financial and social factors to the burden of caretaking and household responsibilities," (2023). These numbers indicate that the curated midcentury sterotypes remain relevent today.

This project will take a look at how the level of aggreement with the statement, "It is more for a wife to help her husband's career than to have one herself," is influenced and how the level of agreement has changed over time.

## Dataset Description

This dataset is from the General Social Survey (GSS) which has conducted research from 1972 on American Society. There are 15266 obervations (rows) with 6 variables (columns). The variables are *year*, *age*, *sex*, *race*, *fehelp*, and *era*.

For variable *fehelp*, repsondents state whether they 1=Strongly Agree to 4 = Strongly Disagree with the statement, "It is more for a wife to help her husband's career than to have one herself." (Please note: this order is reversed-see mutated data below!) For *era*, repsondents state whether they 1=Strongly Favor to 4 = Strongly Oppose the Equal Rights Amendment (ERA). *Sex* is coded as 1=Male and 2=Female; *race* is coded as 1=While, 2=Black, 3=Other.

## Analysis Plan

As per the *Class Project 2* instructions, this report will begin with **Descriptive Statistics** of the dataset and run **Simple Linear Regression** models and summaries. A scatterplot will give a visual perspective of the linear, log-linear, and cubic models, and with that, an exploration of which is the best fitting model. This report will then explore **Multiple Regression** models to consider the optimal model that can best explain how the level of agreement, *fehelp* is influenced. This consideration will be done through analysis of robust standard errors, reviewing the summaries of the models, and interpreting the F-statistics. The **Results and Conclusion** will report on the best model and if the level of agreement has significantly changed over time.

## Dataset

```{r}
# Read in data and prepare data
GSS <- read_csv("Nanci_datafolder/GSS.csv", show_col_types = FALSE)

# Mutating *fehelp* to *fehelpI* by reversing the values 1=Strongly Agree through 4=Strongly Disagree to 1=Strongly Disagree through 4=Strongly Agree because it seems more intuitive for graphing. Also, the variables *sex* and *race* were changed from numerical to factor data for analysis. *Sex* and *race* were labeled as coded by GSS, 1=Male and 2=Female and 1=While, 2=Black, and 3=Other.
GSSI <- GSS %>% 
  mutate(fehelpI = case_when(
    fehelp == 1 ~ 4, 
    fehelp == 2 ~ 3, 
    fehelp == 3 ~ 2, 
    fehelp == 4 ~ 1), 
    fehelpIf = factor(fehelpI, levels = c(1, 2, 3, 4), labels = c("Strongly Disagree", "Disagree", "Agree", "Strongly Agree")), 
    race = factor(race, levels = c(1, 2, 3), labels = c("White", "Black", "Other")),
    sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female"))
  )

# Vectors with select variables
vars <- GSSI[c("year", "age", "fehelpI", "sex", "race")]
vars_num <- GSSI[c("year", "age", "fehelpI")]
vars_cat <- GSSI[c("sex","race")]
```

## Descriptive Statistics

```{r}
# Summary
summary(vars)

```

```{r}
# Mean and standard deviation
cbind(GSS_mean = sapply(vars_num, mean), 
      GSS_sd = sapply(vars_num, sd))

```

```{r}
# Frequencies and percentages
Race <- table(GSSI$race)
cbind(Race, prop.table(Race)*100)

Sex <- table(GSSI$sex)
cbind(Sex, prop.table(Sex)*100)

Level_of_Agree <- table(GSSI$fehelpI)
cbind(Level_of_Agree, prop.table(Level_of_Agree)*100)
```

```{r}
# Bar graphs
ggplot(GSSI, aes(fehelpI)) + 
  geom_bar(aes(fill=sex), position = "fill") +
  labs(title = "Husband's Career a Priority by Sex", x = "Level of Agreement", y = "Percent") +
  scale_fill_manual(values = c("Male" = "blue", "Female" = "#FF69B4"))

```

```{r}
# Bar graph to view distribution of *fehelpI*
GSSI %>% ggplot(aes(fehelpI, fill= fehelpIf))+
  geom_bar() + 
  labs(x = "Level of Agreement", y = "Frequency", title = "Husband's Career A Priority" ) +
  scale_fill_brewer(palette = "Set2")
```

## Simple Linear Regression

Below are linear, log-linear, and cubic models and their summaries with *fehelpI* as the dependent variable and *year* as the independent variable. The regression models are displayed on a scatterplot to give a visual perspective of fitting the models to data.

Both variables can be considered continuous data for statistical analysis. The ordinal Likert variable *fehelp* meets the following conditions to be considered continuous: the sample size is large (n=15266); the number of response categories is close to large (4); the intervals between categories in theory are equal, and there is minimal skewness in the distribution of responses. Because the standard errors for nearly equal for both the lm function (which assumes homoscedasticity and independence) and coeftest function (which corrects for heteroscedasticity and possible dependence), it suggests that homoscedasticity and independence assumptions hold.

It is reasonable for this sample can be applied to the broader population over the time period surveyed. It can be expected that new data fed into the linear regression would fit the model.

In comparing the three models, the linear and log-linear appear to be a better fit from the visual perspective on the on the scatterplot. Both models closely follow negative correlation of the variables, that is, as time goes on, the level of agreement with the statement, "It is more for a wife to help her husband's career than to have one herself," decreases. The cubic model appears to subtly curve upward and does not appear to be a good fit to the data.

Along with the graphing perspective, the regression summaries show evidence that the linear and log-linear models are a good fit. While the R-squared values (0.06) and the residual standard errors (0.76) are the same for all three models, the coefficent estimates for the linear and log-linear models are significant, where they are not significant for the cubic model. Coefficient estimates are not statistically significant signal that this can be a weak model.

For the purpose of interpretation, along with the visual and initial analysis of the regression summaries, it appears the linear model would be the best model. See the models and scatterplot below.

```{r}
# Basic linear model and summary
mod_1 <- lm(fehelpI ~ year, GSSI)
summary(mod_1)
coeftest(mod_1, vcov. = vcovHC)
```

```{r}
# Log-linear model and summary
mod_log <- lm(fehelpI ~ log(year), GSSI)
summary(mod_log)
coeftest(mod_log, vcov. = vcovHC)
```

```{r}
# Cubic model and summary
mod_cubic <- lm(fehelpI ~ I(year) + I(year^2) + I(year^3), GSSI)
summary(mod_cubic)
```

```{r}
# Scatterplot with models
GSSI %>% 
  ggplot(aes(year, fehelpI)) +
  geom_point(color = "blue", shape = 21, size = .1, position = position_jitter(width = 0.5, height = 0.5)) + 
  geom_smooth(method = "lm", se = FALSE, aes(color = "Linear Model"), size = 6) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, aes(color = "Cubic Model"), size = 4) +
  geom_smooth(method = "lm", formula = y ~ log(x), se = FALSE, aes(color = "Log-Linear Model"), size = 2, linetype = "dashed") +
  labs(x = "Year", y = "Level of Agreement", title = "Husband's Career a Priority") + 
  theme_minimal() +
  scale_color_manual(values = c("red", "green", "orange"), labels = c("Cubic Model", "Linear Model", "Log-Linear"))
```

## Multiple Regression

Four additional models were run with each subsequent model incorportating an additional predictor variable to the simple regression mod_1, y=*fehelpI* and x=*year*. The other variables were *age*, *sex*, and *race*, and model 5 included interactions of *sex* and *race*. Examining the interaction of *sex* and *race* can capture if together these variables have an effect on the level of agrreement, but may not individually.

Including more variables may lead to a more optimal model. But, at a certain point, too many variables may be overfitting the data by including irrelevant variables and missing patterns or relationships. And, if there are highly correlated predictor variables, multicolinearity, then may be hard to interpret the effects of the individual variables. Analysis was done to find the best model in trying to determine the most relevent influences on the level of agreement.

The robust standard errors were calculated. All the standard errors are considered small (approximately 1/10 or less of the coefficient estimates) and therefore the coefficients estimates seem to be precise. A summary of the regression models shows there was a big increase in the R-squared from model 1 to model 2, from about 0.06 to 0.17. This means that by adding just the variable *age* that there was an 11% increase that explains how the variation of the level of agreement is is effected by the change in the *age*. The R-squared levels off for models 3, 4, and 5 at 0.171, 0.177, 0.178, respectively. This may lead one conclude the the additonal variables and interaction of the *sex* and *race* are not adding value to the model, but examine this closer. With the R-squared and adjusted R-squared equal for models 3 and 4, and that the coefficient estimates are all significant, it woudld be reasonable to say that *sex* and *race* do contribute to the best model. A check for collinearity was done with a correlation matrix and there is no collinearity.

At this point, model 4 is looking like the optimal model. But let's compare this with a restricted model, model 5, by considering the interaction of the variables *sex* and *race*. Notable findings about the interaction of these two variables is that the coefficient estimates are both positive and negative depending the on the levels combined. The coefficient estimates are in comparison to the reference level white/male. For instance, the coefficient estimate for female is negative and statistically significant in comparison the male respondents. In other words, female respondents disagree more with the statement than males. Where as, in comparing other levels, repsondants who identified as Black or Other, the coefficient estimate was positive and statistically significant. This means their level of aggreement was higher white respondents. The only coefficient estimate that was not significantly different from the white/male reference was those that identified as Female/Other race.

Even thought the interaction of the two variables had interesting results, it does not appear to be the best model. In comparing the Sum of Squares Residuals (SSR) of the undrestricted model 4 and restricted model 5, it was found that SSR of the restricted model is less than and close to equal the unrestricted model indicating the interaction *of the variables* sex\* and *race* do not contribute to a better model. And, the p-value of the F-statistic is not less than 0.05 which also suggests that there is not enough evidence to conclude the restricted model is better the unrestricted model.

The F-statistic of all the multiple regression models are large and the p-values are small. This shows there is a relationship between the level of aggreement and the predictor variables. The variation in the level of agreement is influenced by the predictor variables and it is not just random chance.

```{r}
# Models
mod_2 <- lm(fehelpI ~ year + age, GSSI)
mod_3 <- lm(fehelpI ~ year + age + sex, GSSI)
mod_4 <- lm(fehelpI ~ year + age + sex + race, GSSI)
mod_5 <- lm(fehelpI ~ year + age + (sex*race), GSSI)
```

```{r}
# Robust standard errors for corresponding coefficients
rob_se <- list(
  sqrt(diag(vcovHC(mod_1, type = "HC1"))),
  sqrt(diag(vcovHC(mod_2, type = "HC1"))),
  sqrt(diag(vcovHC(mod_3, type = "HC1"))),
  sqrt(diag(vcovHC(mod_4, type = "HC1"))),
  sqrt(diag(vcovHC(mod_5, type = "HC1")))
)
rob_se
```

```{r}
# Summary of the regression models
stargazer(mod_1, mod_2, mod_3, mod_4, mod_5, title = "Regression Results",
          type = "text",  # Use "text" to print the table to the console
          digits = 3,     
          header = TRUE 
)
```
```{r}
# Check for collinearity 
GSSI_num_subset <- GSSI[, c("fehelpI", "year", "age")]
cor(GSSI_num_subset)
# There is no collinearity between the numerical variables.
```
```{r}
# Restricted Model 
# Compute the Sum of Squares Residuals (SSR)
RSSR_GSSI <- sum(mod_5$residuals^2)
RSSR_GSSI

# Unrestricted model
UNR_SSR_GSSI <- sum(mod_4$residuals^2)
UNR_SSR_GSSI

# Compare SSR's
RSSR_GSSI >= UNR_SSR_GSSI

# Compare Restricted and Unrestricted Model 
Fstat_GSSI <- ((RSSR_GSSI-UNR_SSR_GSSI)/1)/(UNR_SSR_GSSI/(nrow(GSSI)-4-1))

# Compute the p-value
pval_Fstat_GSSI <- 1 - pf(Fstat_GSSI, df1 = 1, df2 = nrow(GSSI)-4-1)

# Check if the null is rejected at the 1% significance level
pval_Fstat_GSSI < 0.05

# The SSR of the restricted model is less than, close to equal the unrestricted model indicating the interaction of the variables sex and race do not contribute to a better model. And the p-value of the F-statistic is not less than 0.05 which also suggests that there is not enough evidence to conclude the restricted model is better the unrestricted model. 
```

## Conclusion and Discussion

Based on the observations and data analysis, it is reasonable to conclude that model 4 emerges as the optimal model. Data assumptions were met, and the inclusion of additional variables were carefully explored. As a result, Model 4 fits the data well and the additional variables contribute to the model.

To answer the questions, how has the level of agreement changed over time and is it significant, it can be concluded that the level of agreement has decreased over time and that it is statistically significant. The coefficient estimate for year is -0.03 and the p-value is less than 0.01 therefore showing evidence that the decrease in level of agreement is significant.

```{r}
# Bar graph to view distribution of *fehelpI*
GSSI %>% ggplot(aes(fehelpI, fill= fehelpIf))+
  geom_bar() + 
  labs(x = "Level of Agreement", y = "Frequency", title = "Husband's Career A Priority" ) +
  scale_fill_brewer(palette = "Set2") + 
  facet_wrap(~year, ncol =3)
```
```{r}
ggplot(GSSI, aes(x = factor(year), y = fehelpI, fill = factor(year))) +
  geom_violin() +
  labs(x = "Year", y = "Level of Agreement") +
  ggtitle("Husband's Career a Priority by Year")
```

## Bibliography

Davern, M., Bautista, R, Freese, J., Herd, P., & Morgan, S.L. General Social Survey 1972-2022. Sponsored by National Science Foundation. NORC ed. Chicago: NORC, 2023: NORC at the University of Chicago. gssdataexplorer.norc.org

Morgan, K. (2023, June 22). *Why many women prioritise their partners' jobs*. BBC. https://www.bbc.com/worklife/article/20230620-why-many-women-prioritise-their-partners-jobs

RStudio Team (2020). RStudio: Integrated Development for R. RStudio, PBC, Boston, MA URL 
http://www.rstudio.com/.

Tucker, J. & Vogtman, J.(2022). Resilient but not recovered. After two years of covid-19, women are   still struggling. National Women's Law Center.            https://nwlc.org/wp-content/uploads/2022/03/FINAL-NWLC-Resilient-But-Not-Recovered-3.29.22.pdf

